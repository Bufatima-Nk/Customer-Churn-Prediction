# Customer Churn Prediction Project

This repository contains a data science project focused on predicting customer churn using machine learning techniques. The project was developed as part of the technical application for the Beeline internship program.

## Project Overview

The goal of this project was to predict customer churn in a telecommunications context. The dataset, named `tech_task_dataset.csv`, includes various features related to customer behavior and usage patterns.

## Project Structure

- `tech_task_dataset.csv`: The dataset used for training and testing.
- `tech_task_beeline.ipynb`: Jupyter Notebook file containing the code for data preprocessing, model training, evaluation, and exploratory data analysis (EDA).
- `README.md`: This README file providing an overview of the project.

## Model Performance

The models were evaluated based on test accuracy, precision, recall, and F1-score. Here's a summary of their performance:

- Decision Tree Test Accuracy: 89%
- Random Forest Test Accuracy: 90%
- Gradient Boosting Test Accuracy: 86%

## Key Insights

- Random Forest demonstrated the highest accuracy and consistent performance across multiple metrics.
- Features such as 'Seconds of Use', 'Frequency of use', 'Complains', and 'Subscription Length' were found to be influential in predicting customer churn.

## Conclusion

This project showcases the effectiveness of machine learning models in predicting customer churn. The Random Forest model yielded the best results, providing valuable insights for businesses to enhance customer retention strategies.

## Usage

1. Clone this repository to your local machine.
2. Open the `tech_task_beeline.ipynb` Jupyter Notebook file to explore the project code.
3. Run the notebook cells in sequence for data preprocessing, model training, and evaluation.
4. Review the model evaluation results and visualizations within the notebook.

## Contact Information

For inquiries about this project or any related information, please contact Bufatima N.k. at bufatima.nk@gmail.com .
